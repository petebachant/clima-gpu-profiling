{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import Pkg\n",
    "Pkg.activate(\".\")  # Activates the Project.toml in current directory\n",
    "Pkg.instantiate() # Installs all dependencies\n",
    "Pkg.status()       # Shows the activated environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1",
   "metadata": {},
   "outputs": [],
   "source": [
    "using Revise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify we're running with SLURM GPU allocation\n",
    "println(\"=== GPU Verification ===\")\n",
    "println(\"SLURM_JOB_ID: \", get(ENV, \"SLURM_JOB_ID\", \"not set\"))\n",
    "println(\"SLURM_JOB_GPUS: \", get(ENV, \"SLURM_JOB_GPUS\", \"not set\"))\n",
    "println(\"CUDA_VISIBLE_DEVICES: \", get(ENV, \"CUDA_VISIBLE_DEVICES\", \"not set\"))\n",
    "\n",
    "using CUDA\n",
    "if CUDA.functional()\n",
    "    println(\"✓ CUDA functional\")\n",
    "    println(\"✓ GPU device: \", CUDA.name(CUDA.device()))\n",
    "    println(\"✓ Memory: \", CUDA.totalmem(CUDA.device()) ÷ (1024^3), \" GB\")\n",
    "else\n",
    "    println(\"✗ CUDA not functional!\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENV[\"CLIMACOMMS_DEVICE\"] = \"CUDA\"\n",
    "ENV[\"CLIMACOMMS_CONTEXT\"] = \"SINGLETON\"\n",
    "\n",
    "import ClimaComms\n",
    "ClimaComms.@import_required_backends\n",
    "import Random\n",
    "Random.seed!(1234)\n",
    "import ClimaAtmos as CA\n",
    "\n",
    "config = CA.AtmosConfig(\n",
    "    [\"ClimaAtmos.jl/config/default_configs/default_config.yml\"],\n",
    "    job_id=\"notebook-debugging\"\n",
    ")\n",
    "\n",
    "simulation = CA.get_simulation(config)\n",
    "(; integrator) = simulation;\n",
    "Y₀ = deepcopy(integrator.u);\n",
    "@info \"Compiling benchmark_step!...\"\n",
    "CA.benchmark_step!(integrator, Y₀); # compile first\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CUDA\n",
    "\n",
    "@CUDA.elapsed CA.benchmark_step!(integrator, Y₀, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import CUDA\n",
    "\n",
    "if CUDA.functional()\n",
    "    # Create arrays on GPU\n",
    "    x_gpu = CUDA.randn(1000, 1000)\n",
    "    y_gpu = CUDA.randn(1000, 1000)\n",
    "\n",
    "    # Perform computation on GPU\n",
    "    z_gpu = x_gpu * y_gpu\n",
    "\n",
    "    println(\"GPU computation successful!\")\n",
    "    println(\"Result size: \", size(z_gpu))\n",
    "    println(\"Result type: \", typeof(z_gpu))\n",
    "    println(\"Device: \", CUDA.device(z_gpu))\n",
    "else\n",
    "    println(\"GPU not available - running on CPU\")\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CUDA.functional()\n",
    "    for (i, dev) in enumerate(CUDA.devices())\n",
    "        CUDA.device!(dev)\n",
    "        println(\"GPU $i:\")\n",
    "        println(\"  Name: \", CUDA.name(dev))\n",
    "        println(\"  Compute capability: \", CUDA.capability(dev))\n",
    "        println(\"  Total memory: \", CUDA.totalmem(dev) ÷ (1024^2), \" MB\")\n",
    "        println(\"  Free memory: \", CUDA.available_memory() ÷ (1024^2), \" MB\")\n",
    "    end\n",
    "end"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.11.5",
   "language": "julia",
   "name": "julia-1.11"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
